{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJECT - METHOD - YYMMDD - NPC Targeted Data Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This document provides a pipeline for the import of Targeted data (post TargetLynx pre-processing for example), and any associated sample metadata, followed by summaries and quality control reports of the data (both in sample and feature dimensions), implementation of batch correction and feature selection and output of a final dataset ready for sharing with collaborators and data modeling. See SOP # for further details of requirements, descriptions of expected outputs and options for optimising data quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By default all summary reports (with the exception of the final report) will be output only to this notebook. The notebook (including outputs) can be saved using >File>Save and Checkpoint. However, if html copies of any reports are required these can be automatically saved to the save directory by adding the optional input argument output=saveDir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initial Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toolboxPath = '/local path to npyc-toolbox/phenomecentre/npyc-toolbox'\n",
    "\n",
    "TargetlynxDataPath1 = '/path to Targetlynx file/PROJECT dataset PIfile Batch1.xml'\n",
    "TargetlynxDataPath2 = '/path to Targetlynx file/PROJECT dataset PIfile Batch2.xml'\n",
    "calibrationReportPath1 = '/path to calibration report/PROJECT dataset calibration report file1.csv'\n",
    "calibrationReportPath2 = '/path to calibration report/PROJECT dataset calibration report file2.csv'\n",
    "nmrRawDataPath  = '/path to NMR data folder/'\n",
    "nmrRawDataPath1 = '/path to NMR data folder/Rack01 date/'\n",
    "nmrRawDataPath2 = '/path to NMR data folder/Rack02 date/'\n",
    "\n",
    "basicCsvFilePath = '/path to basicCSV file/PROJECT dataset basicCsvMetadata.csv'\n",
    "manifestPath = '/path to subject information file/PROJECT SubjectINFOfile.csv'\n",
    "\n",
    "saveDir = '/path to save directory/Projects/PROJECT/METHOD DATE/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import pandas\n",
    "import numpy\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(toolboxPath)\n",
    "import nPYc\n",
    "import copy\n",
    "from nPYc.enumerations import VariableType, DatasetLevel, AssayRole, SampleType, CalibrationMethod, QuantificationType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date and version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from nPYc.__init__ import __version__ as version\n",
    "print('Run with branch ' + version + ' on ' + datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create saveDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(saveDir):\n",
    "    os.makedirs(saveDir)\n",
    "    os.makedirs(os.path.join(saveDir, 'data objects'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import Data and Sample Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import acquired data and associated acquisition parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### fileType = 'TargetLynx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import each plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load each plate\n",
    "targetedData1 = nPYc.TargetedDataset(TargetlynxDataPath1, fileType='TargetLynx', calibrationReportPath=calibrationReportPath1, sop='OxylipinMS')\n",
    "targetedData2 = nPYc.TargetedDataset(TargetlynxDataPath2, fileType='TargetLynx', calibrationReportPath=calibrationReportPath2, sop='OxylipinMS')\n",
    "\n",
    "# Further options are accepted:\n",
    "#\n",
    "# Other SOP\n",
    "# sop='AminoAcidMS'\n",
    "#\n",
    "# Don't filter out Internal Standards (default False)\n",
    "# keepIS = True\n",
    "#\n",
    "# Change the samples to process based on MassLynx SampleType (default ['Study Sample','QC'])\n",
    "# sampleTypeToProcess = ['Study Sample','QC','Blank','Other']\n",
    "#\n",
    "# To replace values <LLOQ by the noise concentration equivalent (default replace by -inf)\n",
    "# noiseFilled = True\n",
    "#   To select the calibration sample use for response reference (default None, use the middle of the calibration curve)\n",
    "#   responseReference = str or list of str\n",
    "#\n",
    "# To replace only <LLOQ (default False,  both <LLOQ and >ULOQ)\n",
    "# onlyLLOQ = True\n",
    "#\n",
    "# To keep peak caracteristics (default False) (peak area, peak response, peak concentration deviation, peak integration flag, peak RT) in self.peakInfo and self.calibration['calibPeakInfo']\n",
    "# keepPeakInfo = True\n",
    "#\n",
    "# To keep import exclusions in sampleMetadataExcluded,... (default False)\n",
    "# keepExcluded = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Bruker Quant-UR\n",
    "### fileType = 'Bruker Quantification', sop='BrukerQuant-UR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load plate separately, or from a parent folder, all sub-folders will be searched\n",
    "#tData = nPYc.TargetedDataset(nmrRawDataPath, fileType='Bruker Quantification', sop='BrukerQuant-UR', fileNamePattern='.*?urine_quant_report_b\\.xml$', unit='mmol/mol Crea')\n",
    "targetedData1 = nPYc.TargetedDataset(nmrRawDataPath1, fileType='Bruker Quantification', sop='BrukerQuant-UR', fileNamePattern='.*?urine_quant_report_b\\.xml$', unit='mmol/mol Crea')\n",
    "targetedData2 = nPYc.TargetedDataset(nmrRawDataPath2, fileType='Bruker Quantification', sop='BrukerQuant-UR', fileNamePattern='.*?urine_quant_report_b\\.xml$', unit='mmol/mol Crea')\n",
    "\n",
    "# Further options are accepted:\n",
    "#\n",
    "# To provide the regex to recognise the data xml files\n",
    "# fileNamePattern = ''\n",
    "#\n",
    "# To select the right pdata (default 1)\n",
    "# pdata = 1\n",
    "#\n",
    "# If the same features are present multiple times with different units, use 'unit' to only select a specific unit (default None, all entries)\n",
    "# unit = 'mmol/L'\n",
    "# unit = 'mmol/mol Crea'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Bruker BI-LISA\n",
    "### fileType = 'Bruker Quantification', sop='BrukerBI-LISA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load plate separately, or from a parent folder, all sub-folders will be searched\n",
    "#tData = nPYc.TargetedDataset(nmrRawDataPath, fileType='Bruker Quantification', sop='BrukerBI-LISA', fileNamePattern='.*?results\\.xml$')\n",
    "targetedData1 = nPYc.TargetedDataset(nmrRawDataPath1, fileType='Bruker Quantification', sop='BrukerBI-LISA', fileNamePattern='.*?results\\.xml$')\n",
    "targetedData2 = nPYc.TargetedDataset(nmrRawDataPath2, fileType='Bruker Quantification', sop='BrukerBI-LISA', fileNamePattern='.*?results\\.xml$')\n",
    "\n",
    "# Further options are accepted:\n",
    "#\n",
    "# To provide the regex to recognise the data xml files\n",
    "# fileNamePattern = ''\n",
    "#\n",
    "# To select the right pdata (default 1)\n",
    "# pdata = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Merge all plates in a single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge imported plates\n",
    "tData = targetedData1 + targetedData2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tData.name = 'Targeted Project'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Match acquired samples to Sample File Name (Basic CSV file) and subject information (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tData.addSampleInfo(descriptionFormat='Basic CSV', filePath=basicCsvFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tData.addSampleInfo(descriptionFormat='NPC LIMS', filePath=limsFilePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Sample summary\n",
    "Samples acquired and acquisition structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nPYc.reports.generateReport(tData, 'sample summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To exclude any samples of 'Unknown' type:\n",
    "# tData.excludeSamples(tData.sampleMetadata[pandas.isnull(tData.sampleMetadata['Sample Base Name'])]['Sample File Name'], on='Sample File Name', message='Unknown type')\n",
    "\n",
    "# Then apply masks:\n",
    "# tData.applyMasks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge Limits of Quantification across all plates\n",
    "Assess the impact of the common Limits of Quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nPYc.reports.generateReport(tData, reportType='merge LOQ assessment')\n",
    "\n",
    "# To change the number of plots on each row\n",
    "# numberPlotPerRowLOQ = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the new LOQ are suitable, merge Limits of Quantification. Otherwise some batch might have to be reprocessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update the limits of quantification, keeping the lowest common denominator across all batch: highest LLOQ, lowest ULOQ\n",
    "tData.mergeLimitsOfQuantification()\n",
    "\n",
    "# To keep each batch LOQ (default False)\n",
    "# keepBatchLOQ = True\n",
    "#\n",
    "# To replace only <LLOQ (default False,  both <LLOQ and >ULOQ)\n",
    "# onlyLLOQ = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save/load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(tData, open(os.path.join(saveDir, 'data objects', tData.name + \"_targetedDataImported.p\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tData = pickle.load( open('path to data objects/targetedDataImported.p', \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Quality check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nPYc.reports.generateReport(tData, 'feature summary')\n",
    "\n",
    "# To modify the Accuracy and Precision percentage (default +/-20%)\n",
    "# Accuracy 80%-120%, Precision 0-20%\n",
    "#percentRange = 20\n",
    "#percentRange = None\n",
    "\n",
    "# To change the number of plots on each row\n",
    "# numberPlotPerRowFeature = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Analytical Multivariate Quality Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tData.updateMasks(sampleTypes=[SampleType.StudySample, SampleType.StudyPool, SampleType.ExternalReference], filterFeatures=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run analytical multivariate QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVD does not accept missing values\n",
    "try:\n",
    "    PCAmodelAnalytical = nPYc.multivariate.exploratoryAnalysisPCA(tData, withExclusions=True, scaling=1.0)\n",
    "    nPYc.reports.multivariateReport.multivariateQCreport(tData, PCAmodelAnalytical, reportType='analytical', withExclusions=True)\n",
    "except ValueError:\n",
    "    print('Multivariate analysis is not currently possible with values <LLOQ or >ULOQ.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IF REQUIRED: generate interactive scores and loadings plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Interactive scores plot, e.g., plotting the scores for the first two components coloured by run order\n",
    "\n",
    "# data = nPYc.plotting.plotScoresInteractive(PCAmodelAnalytical, 'Run Order', components=[1, 2])\n",
    "# iplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Interactive loadings plot, e.g., plotting the loadings for component 2\n",
    "\n",
    "# data = nPYc.plotting.plotLoadingsInteractive(PCAmodelAnalytical, component=2)\n",
    "# iplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Save QC Reports for Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qcDir = os.path.join(saveDir, 'QC')\n",
    "if not os.path.exists(qcDir):\n",
    "    os.makedirs(qcDir)\n",
    "nPYc.reports.generateReport(tData, 'sample summary', output=qcDir)\n",
    "nPYc.reports.generateReport(tData, 'feature summary', withExclusions=True, percentRange=20, output=qcDir)\n",
    "try:\n",
    "    PCAmodelAnalytical = nPYc.multivariate.exploratoryAnalysisPCA(tData, withExclusions=True, scaling=1.0)\n",
    "    nPYc.reports.multivariateReport.multivariateQCreport(tData, PCAmodelAnalytical, reportType='analytical', withExclusions=True, output=qcDir)\n",
    "except ValueError:\n",
    "    print('Multivariate analysis is not currently possible with values <LLOQ or >ULOQ.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Finalise and export dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the samples (default is SampleType.StudySample and SampleType.StudyPool samples only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tData.updateMasks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IF REQUIRED: remove features only Monitored and not quantified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tData.updateMasks(filterSamples=False, quantificationTypes=[QuantificationType.IS, QuantificationType.QuantOwnLabeledAnalogue, QuantificationType.QuantAltLabeledAnalogue, QuantificationType.QuantOther])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate PCA model with updated settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PCAmodelAnalytical = nPYc.multivariate.exploratoryAnalysisPCA(tData, withExclusions=True, scaling=1.0)\n",
    "\n",
    "nPYc.reports.multivariateReport.multivariateQCreport(tData, reportType='analytical', withExclusions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check final dataset output if current masks applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nPYc.reports.generateReport(tData, 'final report', withExclusions=True, pcaModel=PCAmodelAnalytical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tData.applyMasks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Export final dataset\n",
    "tData.exportDataset(destinationPath=saveDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Export final summary report\n",
    "#nPYc.reports.generateReport(tData, 'final report', output=saveDir, pcaModel=None)\n",
    "nPYc.reports.generateReport(tData, 'final report', output=saveDir, pcaModel=PCAmodelAnalytical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To export combined dataset (e.g., format for SIMCA)\n",
    "tData.exportDataset(destinationPath=saveDir, saveFormat='UnifiedCSV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Biological Multivariate Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keep study samples only, but all features\n",
    "tData.updateMasks(sampleTypes=[SampleType.StudySample], filterFeatures=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    PCAmodelBiological = nPYc.reports.multivariateReport.multivariateQCreport(tData, reportType='biological', withExclusions=True, scale_method='uv')\n",
    "except ValueError:\n",
    "    print('Multivariate analysis is not currently possible with values <LLOQ or >ULOQ.')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
